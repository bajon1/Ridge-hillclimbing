{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "535577a9cbaf6171"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.059104Z",
     "start_time": "2026-01-12T19:15:17.343882Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, average_precision_score, classification_report, fbeta_score, accuracy_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import optuna\n",
    "import statsmodels.api as sm\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import custom_map"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominikmika/PycharmProjects/3.11/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.071230Z",
     "start_time": "2026-01-12T19:15:18.059698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(custom_map)"
   ],
   "id": "5988cff7445abe68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'custom_map' from '/Users/dominikmika/PycharmProjects/Ridge-hillclimbing/custom_map.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "6959be082891959c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.100096Z",
     "start_time": "2026-01-12T19:15:18.072549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "bmi_median = data['bmi'].median()\n",
    "data['bmi'] = data['bmi'].fillna(bmi_median)\n",
    "\n",
    "target = \"stroke\"\n",
    "\n",
    "categorical_features = data.select_dtypes(['object']).columns.tolist()\n",
    "numerical_features = data.select_dtypes(['float64', 'int64']).columns.drop('id')\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True, dtype=float)\n",
    "data = data.drop('id', axis=1)\n",
    "\n",
    "binary_features = ['hypertension', 'heart_disease', 'stroke', 'Residence_type_Urban', 'ever_married_Yes', 'gender_Male']\n",
    "\n",
    "numerical_features = numerical_features.drop(['hypertension', 'heart_disease', 'stroke'])\n",
    "numerical_binary_features = numerical_features.union(binary_features)\n",
    "\n",
    "categorical_features = [\n",
    "    col for col in data.columns\n",
    "    if any(col.startswith(c + \"_\") for c in categorical_features)\n",
    "]\n",
    "\n",
    "categorical_features.extend(binary_features)\n",
    "\n",
    "print(\"Categorical: \", categorical_features, '\\n', \"Numerical: \", numerical_features, '\\n', \"Numerical and binary: \", numerical_binary_features)\n",
    "\n"
   ],
   "id": "42be55a91ccd00e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical:  ['gender_Male', 'gender_Other', 'ever_married_Yes', 'work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children', 'Residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes', 'hypertension', 'heart_disease', 'stroke', 'Residence_type_Urban', 'ever_married_Yes', 'gender_Male'] \n",
      " Numerical:  Index(['age', 'avg_glucose_level', 'bmi'], dtype='object') \n",
      " Numerical and binary:  Index(['Residence_type_Urban', 'age', 'avg_glucose_level', 'bmi',\n",
      "       'ever_married_Yes', 'gender_Male', 'heart_disease', 'hypertension',\n",
      "       'stroke'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.117866Z",
     "start_time": "2026-01-12T19:15:18.101565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, shuffle=True)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "575661370130950",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.125298Z",
     "start_time": "2026-01-12T19:15:18.118711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## hard coding because of stochasticity\n",
    "\n",
    "all_features = [\"age\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\",\n",
    "                \"bmi\", \"gender_Male\", \"gender_Other\", \"ever_married_Yes\",\n",
    "                \"work_type_Never_worked\", \"work_type_Private\", \"work_type_Self-employed\",\n",
    "                \"work_type_children\", \"Residence_type_Urban\",\n",
    "                \"smoking_status_formerly smoked\", \"smoking_status_never smoked\",\n",
    "                \"smoking_status_smokes\"]\n",
    "\n",
    "boruta_features = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "\n",
    "corr_features = ['age', 'heart_disease', 'avg_glucose_level', 'hypertension', 'ever_married_Yes',\n",
    "                 'smoking_status_formerly smoked', 'work_type_Self-employed', 'bmi']\n",
    "\n",
    "mi_features = [\"age\", \"hypertension\", \"gender_Other\",\n",
    "               \"work_type_Private\", \"smoking_status_formerly smoked\"]\n",
    "\n",
    "rfe_features = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'gender_Male', 'ever_married_Yes',\n",
    "                'work_type_Never_worked', 'work_type_Private', 'work_type_Self-employed', 'work_type_children',\n",
    "                'Residence_type_Urban', 'smoking_status_formerly smoked', 'smoking_status_never smoked', 'smoking_status_smokes',\n",
    "                'bmi']\n",
    "\n",
    "FEATURE_SETS = {\n",
    "    \"all\": all_features,\n",
    "    \"boruta\": boruta_features,\n",
    "    \"correlation\": corr_features,\n",
    "    \"mi\": mi_features,\n",
    "    \"rfe\": rfe_features\n",
    "}"
   ],
   "id": "906e8c35c1ae4419",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.141144Z",
     "start_time": "2026-01-12T19:15:18.125800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_all = X_train[all_features] # all features\n",
    "X_train_boruta = X_train[boruta_features].copy() # boruta selection\n",
    "X_train_corr = X_train[corr_features].copy() # cmap correlation\n",
    "X_train_mi = X_train[mi_features].copy() # correlation, mi & clustering\n",
    "X_train_rfe = X_train[rfe_features].copy() # rfecv\n",
    "\n",
    "data = {\n",
    "    \"Method\": [\n",
    "        \"All features\",\n",
    "        \"Boruta\",\n",
    "        \"Corelation\",\n",
    "        \"Mutual Information\",\n",
    "        \"RFE\"\n",
    "    ],\n",
    "    \"Feature quantity\": [\n",
    "        len(all_features),\n",
    "        len(boruta_features),\n",
    "        len(corr_features),\n",
    "        len(mi_features),\n",
    "        len(rfe_features)\n",
    "    ],\n",
    "    \"Feature name\": [\n",
    "        \", \".join(all_features),\n",
    "        \", \".join(boruta_features),\n",
    "        \", \".join(corr_features),\n",
    "        \", \".join(mi_features),\n",
    "        \", \".join(rfe_features)\n",
    "    ]\n",
    "}\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ],
   "id": "14ee39ff54c3bb8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Method  Feature quantity  \\\n",
       "0        All features                16   \n",
       "1              Boruta                 3   \n",
       "2          Corelation                 8   \n",
       "3  Mutual Information                 5   \n",
       "4                 RFE                15   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                              Feature name  \n",
       "0  age, hypertension, heart_disease, avg_glucose_level, bmi, gender_Male, gender_Other, ever_married_Yes, work_type_Never_worked, work_type_Private, work_type_Self-employed, work_type_children, Residence_type_Urban, smoking_status_formerly smoked, smoking_status_never smoked, smoking_status_smokes  \n",
       "1                                                                                                                                                                                                                                                                              age, avg_glucose_level, bmi  \n",
       "2                                                                                                                                                                      age, heart_disease, avg_glucose_level, hypertension, ever_married_Yes, smoking_status_formerly smoked, work_type_Self-employed, bmi  \n",
       "3                                                                                                                                                                                                                       age, hypertension, gender_Other, work_type_Private, smoking_status_formerly smoked  \n",
       "4                age, hypertension, heart_disease, avg_glucose_level, gender_Male, ever_married_Yes, work_type_Never_worked, work_type_Private, work_type_Self-employed, work_type_children, Residence_type_Urban, smoking_status_formerly smoked, smoking_status_never smoked, smoking_status_smokes, bmi  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Feature quantity</th>\n",
       "      <th>Feature name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All features</td>\n",
       "      <td>16</td>\n",
       "      <td>age, hypertension, heart_disease, avg_glucose_level, bmi, gender_Male, gender_Other, ever_married_Yes, work_type_Never_worked, work_type_Private, work_type_Self-employed, work_type_children, Residence_type_Urban, smoking_status_formerly smoked, smoking_status_never smoked, smoking_status_smokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boruta</td>\n",
       "      <td>3</td>\n",
       "      <td>age, avg_glucose_level, bmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corelation</td>\n",
       "      <td>8</td>\n",
       "      <td>age, heart_disease, avg_glucose_level, hypertension, ever_married_Yes, smoking_status_formerly smoked, work_type_Self-employed, bmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mutual Information</td>\n",
       "      <td>5</td>\n",
       "      <td>age, hypertension, gender_Other, work_type_Private, smoking_status_formerly smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFE</td>\n",
       "      <td>15</td>\n",
       "      <td>age, hypertension, heart_disease, avg_glucose_level, gender_Male, ever_married_Yes, work_type_Never_worked, work_type_Private, work_type_Self-employed, work_type_children, Residence_type_Urban, smoking_status_formerly smoked, smoking_status_never smoked, smoking_status_smokes, bmi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ridge Hill Climbing",
   "id": "9a317e74166dcbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.249791Z",
     "start_time": "2026-01-12T19:15:18.171945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "storage_url = \"sqlite:///optuna_studies.db\"\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "MODELS = [\n",
    "    \"logreg\", \"knn\", \"svm\", \"gnb\", \"dt\",\n",
    "    \"rf\", \"ada\", \"gb\", \"extra\",\n",
    "    \"lgbm\", \"xgb\", \"cat\"\n",
    "]\n",
    "\n",
    "SMOTE_MODELS = {\"logreg\", \"knn\", \"svm\", \"gnb\"}"
   ],
   "id": "cd368a207abe3fee",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.331012Z",
     "start_time": "2026-01-12T19:15:18.316314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_all_model_predictions(\n",
    "    MODELS, FEATURE_SETS,\n",
    "    X_train, y_train,\n",
    "    X_test\n",
    "):\n",
    "    train_preds = []\n",
    "    test_preds = []\n",
    "    model_names = []\n",
    "\n",
    "    for feature_name, feature_list in FEATURE_SETS.items():\n",
    "        X_train_sel = X_train[feature_list]\n",
    "        X_test_sel = X_test[feature_list]\n",
    "\n",
    "        for model_name in MODELS:\n",
    "            study_name = f\"{model_name}_{feature_name}_prob\"\n",
    "\n",
    "            with open(f\"models/prob_f1/{study_name}.pkl\", \"rb\") as f:\n",
    "                artifact = pickle.load(f)\n",
    "\n",
    "            model = artifact[\"model\"]\n",
    "\n",
    "            p_train = model.predict_proba(X_train_sel)[:, 1]\n",
    "            p_test = model.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "            train_preds.append(p_train)\n",
    "            test_preds.append(p_test)\n",
    "            model_names.append(study_name)\n",
    "\n",
    "    P_train = np.column_stack(train_preds)\n",
    "    P_test = np.column_stack(test_preds)\n",
    "\n",
    "    return P_train, P_test, model_names\n"
   ],
   "id": "4d40b8779ff0f6dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.352777Z",
     "start_time": "2026-01-12T19:15:18.349696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensemble_f1_score(P, y, weights, threshold, alpha=0.01):\n",
    "    ensemble_proba = P @ weights\n",
    "    y_pred = (ensemble_proba >= threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    ridge_penalty = alpha * np.sum(weights ** 2)\n",
    "\n",
    "    return f1 - ridge_penalty\n"
   ],
   "id": "7d7f168541c6a0a9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.373648Z",
     "start_time": "2026-01-12T19:15:18.369693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hill_climbing_ensemble(\n",
    "    P_train, y_train,\n",
    "    step=0.02,\n",
    "    max_iter=200,\n",
    "    alpha=0.01\n",
    "):\n",
    "    n_models = P_train.shape[1]\n",
    "    weights = np.ones(n_models) / n_models\n",
    "\n",
    "    best_threshold, _ = find_best_f1_threshold_dummy(P_train, y_train, weights)\n",
    "    best_score = ensemble_f1_score(P_train, y_train, weights, best_threshold, alpha)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        improved = False\n",
    "\n",
    "        for i in range(n_models):\n",
    "            for delta in [+step, -step]:\n",
    "                new_weights = weights.copy()\n",
    "                new_weights[i] += delta\n",
    "\n",
    "                if new_weights[i] < 0:\n",
    "                    continue\n",
    "\n",
    "                new_weights /= new_weights.sum()\n",
    "\n",
    "                thr, _ = find_best_f1_threshold_dummy(\n",
    "                    P_train, y_train, new_weights\n",
    "                )\n",
    "\n",
    "                score = ensemble_f1_score(\n",
    "                    P_train, y_train, new_weights, thr, alpha\n",
    "                )\n",
    "\n",
    "                if score > best_score:\n",
    "                    weights = new_weights\n",
    "                    best_score = score\n",
    "                    best_threshold = thr\n",
    "                    improved = True\n",
    "\n",
    "        if not improved:\n",
    "            break\n",
    "\n",
    "    return weights, best_threshold, best_score\n"
   ],
   "id": "219ce64cb6ee72bc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:18.392713Z",
     "start_time": "2026-01-12T19:15:18.389694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_best_f1_threshold_dummy(P, y, weights, thresholds=np.linspace(0.01, 0.5, 50)):\n",
    "    ensemble_proba = P @ weights\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_thr = 0.5\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (ensemble_proba >= t).astype(int)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = t\n",
    "\n",
    "    return best_thr, best_f1\n"
   ],
   "id": "25fc1e52244d4a25",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:15:19.589015Z",
     "start_time": "2026-01-12T19:15:18.393047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "P_train, P_test, model_names = load_all_model_predictions(\n",
    "    MODELS, FEATURE_SETS,\n",
    "    X_train, y_train,\n",
    "    X_test\n",
    ")\n",
    "\n",
    "weights, best_thr, train_score = hill_climbing_ensemble(\n",
    "    P_train, y_train,\n",
    "    step=0.02,\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "y_test_pred = (P_test @ weights >= best_thr).astype(int)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"ENSEMBLE RESULTS\")\n",
    "print(\"----------------\")\n",
    "print(f\"F1 train: {train_score:.4f}\")\n",
    "print(f\"F1 test : {f1_test:.4f}\")\n",
    "print(f\"Threshold: {best_thr:.3f}\")\n",
    "\n",
    "for name, w in sorted(zip(model_names, weights), key=lambda x: -x[1]):\n",
    "    if w > 0.01:\n",
    "        print(f\"{name:40s}  weight={w:.3f}\")\n",
    "\n",
    "os.makedirs(\"models/hc\", exist_ok=True)\n",
    "\n",
    "hc_path = \"models/hc/hc_ensemble_v3.pkl\"\n",
    "\n",
    "hc_artifact = {\n",
    "    \"type\": \"hill_climbing_ensemble\",\n",
    "    \"weights\": weights,\n",
    "    \"threshold\": best_thr,\n",
    "    \"model_names\": model_names,\n",
    "    \"f1_train\": train_score\n",
    "}\n",
    "\n",
    "with open(hc_path, \"wb\") as f:\n",
    "    pickle.dump(hc_artifact, f)"
   ],
   "id": "6dd62a1fa51fe4f8",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- bmi\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m P_train, P_test, model_names = \u001B[43mload_all_model_predictions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mMODELS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mFEATURE_SETS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m weights, best_thr, train_score = hill_climbing_ensemble(\n\u001B[32m      8\u001B[39m     P_train, y_train,\n\u001B[32m      9\u001B[39m     step=\u001B[32m0.02\u001B[39m,\n\u001B[32m     10\u001B[39m     alpha=\u001B[32m0.01\u001B[39m\n\u001B[32m     11\u001B[39m )\n\u001B[32m     13\u001B[39m y_test_pred = (P_test @ weights >= best_thr).astype(\u001B[38;5;28mint\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 22\u001B[39m, in \u001B[36mload_all_model_predictions\u001B[39m\u001B[34m(MODELS, FEATURE_SETS, X_train, y_train, X_test)\u001B[39m\n\u001B[32m     18\u001B[39m     artifact = pickle.load(f)\n\u001B[32m     20\u001B[39m model = artifact[\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m p_train = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_sel\u001B[49m\u001B[43m)\u001B[49m[:, \u001B[32m1\u001B[39m]\n\u001B[32m     23\u001B[39m p_test = model.predict_proba(X_test_sel)[:, \u001B[32m1\u001B[39m]\n\u001B[32m     25\u001B[39m train_preds.append(p_train)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/3.11/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:858\u001B[39m, in \u001B[36mPipeline.predict_proba\u001B[39m\u001B[34m(self, X, **params)\u001B[39m\n\u001B[32m    856\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _routing_enabled():\n\u001B[32m    857\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iter(with_final=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m858\u001B[39m         Xt = \u001B[43mtransform\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    859\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.steps[-\u001B[32m1\u001B[39m][\u001B[32m1\u001B[39m].predict_proba(Xt, **params)\n\u001B[32m    861\u001B[39m \u001B[38;5;66;03m# metadata routing enabled\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/3.11/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:316\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    317\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    318\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    319\u001B[39m         return_tuple = (\n\u001B[32m    320\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    321\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    322\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/3.11/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1094\u001B[39m, in \u001B[36mStandardScaler.transform\u001B[39m\u001B[34m(self, X, copy)\u001B[39m\n\u001B[32m   1091\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m   1093\u001B[39m copy = copy \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.copy\n\u001B[32m-> \u001B[39m\u001B[32m1094\u001B[39m X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1095\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1096\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1097\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1098\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1099\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1100\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43msupported_float_dtypes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_device\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1101\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1102\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1103\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1105\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sparse.issparse(X):\n\u001B[32m   1106\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.with_mean:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/3.11/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2877\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2793\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mvalidate_data\u001B[39m(\n\u001B[32m   2794\u001B[39m     _estimator,\n\u001B[32m   2795\u001B[39m     /,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2801\u001B[39m     **check_params,\n\u001B[32m   2802\u001B[39m ):\n\u001B[32m   2803\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001B[39;00m\n\u001B[32m   2804\u001B[39m \n\u001B[32m   2805\u001B[39m \u001B[33;03m    This helper function should be used in an estimator that requires input\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2875\u001B[39m \u001B[33;03m        validated.\u001B[39;00m\n\u001B[32m   2876\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2877\u001B[39m     \u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2878\u001B[39m     tags = get_tags(_estimator)\n\u001B[32m   2879\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m tags.target_tags.required:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/3.11/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2729\u001B[39m, in \u001B[36m_check_feature_names\u001B[39m\u001B[34m(estimator, X, reset)\u001B[39m\n\u001B[32m   2726\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[32m   2727\u001B[39m     message += \u001B[33m\"\u001B[39m\u001B[33mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m2729\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[31mValueError\u001B[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- bmi\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def inspect_hc_ensemble(path, min_weight=0.01):\n",
    "    with open(path, \"rb\") as f:\n",
    "        artifact = pickle.load(f)\n",
    "\n",
    "    print(f\"\\nðŸ“¦ ENSEMBLE: {path}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    print(f\"F1 train : {artifact.get('f1_train', 'N/A')}\")\n",
    "    print(f\"Threshold: {artifact.get('threshold')}\")\n",
    "\n",
    "    model_names = artifact[\"model_names\"]\n",
    "    weights = artifact[\"weights\"]\n",
    "\n",
    "    for name, w in sorted(zip(model_names, weights), key=lambda x: -x[1]):\n",
    "        if w >= min_weight:\n",
    "            print(f\"{name:40s} weight={w:.4f}\")"
   ],
   "id": "afd38873433a2efc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for p in Path(\"models/hc\").glob(\"hc_ensemble*.pkl\"):\n",
    "    inspect_hc_ensemble(p)\n"
   ],
   "id": "47b75bec5d311dd8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
