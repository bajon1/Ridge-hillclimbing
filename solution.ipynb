{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "8dae3f798e3de614"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import optuna\n",
    "import statsmodels.api as sm\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import custom_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(custom_map)"
   ],
   "id": "6b26b5db5d2c60ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data and feature engineering",
   "id": "121131a70010e491"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "data.info()"
   ],
   "id": "2691a56cef39f5af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target = \"stroke\"\n",
    "\n",
    "categorical_features = data.select_dtypes(['object']).columns.tolist()\n",
    "numerical_features = data.select_dtypes(['float64', 'int64']).columns.drop('id')\n",
    "categorical_features.append('stroke')\n",
    "\n",
    "print(categorical_features, '\\n', numerical_features)\n",
    "\n",
    "data.head()"
   ],
   "id": "463ad54d6139cad9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data[numerical_features].hist(bins=30, figsize=(15, 10), color=\"teal\", edgecolor='black')\n",
    "plt.suptitle(\"Histogramy zmiennych numerycznych\", fontsize=16)\n",
    "plt.show()"
   ],
   "id": "61a7e0031277b739",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bmi_median = data['bmi'].median()\n",
    "bmi_mean = data['bmi'].mean()\n",
    "print(bmi_median, bmi_mean)\n",
    "\n",
    "data['bmi'] = data['bmi'].fillna(bmi_median)"
   ],
   "id": "6fc114b4fdc24314",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nrows, ncols = 2, 3\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 9))\n",
    "axes = axes.flat\n",
    "\n",
    "for ax, col in zip(axes, categorical_features):\n",
    "    sizes = data[col].value_counts()\n",
    "    labels = sizes.index.astype(str)\n",
    "\n",
    "    ax.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90)\n",
    "    ax.set_title(col)\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "218adfb038318078",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical_features.remove('stroke')\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True, dtype=float)\n",
    "data = data.drop('id', axis=1)"
   ],
   "id": "2f2b3e887fbe79f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlation_data = data[numerical_features].corr()\n",
    "\n",
    "n_features = data[numerical_features].shape[1]\n",
    "n = data[numerical_features].size/data[numerical_features].shape[1]\n",
    "custom_map.cmap_pearson(n_features, n, 0.1)\n",
    "print(custom_map.cmap_pearson(n_features, n, 0.1))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "sns.heatmap(correlation_data, annot=True, fmt=\".2f\", cmap=\"bajon\", vmin=-1, vmax=1) #tab20b\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "271963957020ba4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlation_data = data.corr()\n",
    "\n",
    "n_features = data[numerical_features].shape[1]\n",
    "n = data[numerical_features].size/data[numerical_features].shape[1]\n",
    "custom_map.cmap_pearson(n_features, n, 0.1)\n",
    "print(custom_map.cmap_pearson(n_features, n, 0.1))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "sns.heatmap(correlation_data, annot=True, fmt=\".2f\", cmap=\"bajon\", vmin=-1, vmax=1) #tab20b\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "dea6d064ee49d997",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, shuffle=True)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "5bdb49ad0ebe8d12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature selection",
   "id": "652ec9d82144c9c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "boruta = BorutaPy(\n",
    "    estimator=rf,\n",
    "    n_estimators='auto',   # lub liczba\n",
    "    max_iter=100,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "boruta.fit(X_train, y_train)\n",
    "\n",
    "selected_mask = boruta.support_\n",
    "selected_features = np.where(selected_mask)[0]\n",
    "print(\"Wybrane cechy (indeksy):\", selected_features)\n",
    "print(\"Ranking:\", boruta.ranking_)"
   ],
   "id": "18dba6279078c87a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selected_indices = np.where(boruta.support_)[0]\n",
    "boruta_features = X_train.columns[selected_indices].tolist()\n",
    "\n",
    "boruta_features"
   ],
   "id": "898d72e6349b3185",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_features = data.corr()[target].sort_values(ascending=False)\n",
    "corr_features = corr_features[corr_features > custom_map.cmap_pearson(n_features, n, 0.1)['r_crit']].index.tolist()\n",
    "\n",
    "corr_features.remove('stroke')\n",
    "corr_features"
   ],
   "id": "9fab026249573ff9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data[corr_features].head()",
   "id": "932ca4bfa2aac37b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_chosen = data[corr_features].copy()\n",
    "X_scaled = scaler.fit_transform(X_chosen)\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=3,\n",
    "    random_state=42,\n",
    "    n_init=20\n",
    ")\n",
    "\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "X_chosen[\"cluster\"] = clusters\n",
    "\n",
    "X_chosen[\"cluster\"].describe()"
   ],
   "id": "9d22c54d106c32ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_train.info()",
   "id": "19eab7f2b5074a2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_idx = np.random.choice(len(X_train), size=int(X_train.size/20), replace=False)\n",
    "\n",
    "mi = mutual_info_regression(X_train.iloc[sample_idx], y_train.iloc[sample_idx])\n",
    "mi_df = pd.DataFrame({\"Feature\": X_train.columns, \"Mutual Information\": mi})\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(X_train.columns, mi)\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Mutual Information')\n",
    "plt.show()\n",
    "mi_df\n",
    "\n"
   ],
   "id": "ecdf0fe1f088ca69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "names = X_train.columns\n",
    "# 1. Compute Spearman correlation and distance matrix\n",
    "# Assuming X is your dataframe of explanatory variables\n",
    "corr = spearmanr(X).correlation\n",
    "# Ensure the matrix is symmetric (sometimes float errors occur)\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# Convert correlation to a distance matrix\n",
    "dist_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(hierarchy.distance.squareform(dist_matrix))\n",
    "\n",
    "# 2. Visualize the Dendrogram\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=names, ax=ax, leaf_rotation=90\n",
    ")\n",
    "ax.set_title(\"Hierarchical Clustering Dendrogram (Feature Redundancy)\")\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# 3. Select Features\n",
    "# Threshold '1' is common for 1 - abs(corr), but you can adjust based on the plot\n",
    "cluster_ids = hierarchy.fcluster(dist_linkage, t=1, criterion='distance')\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "\n",
    "# Keep only the first feature from each cluster\n",
    "selected_idx = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "mi_features = names[selected_idx]\n",
    "X_reduced = X_train.iloc[:, selected_idx]\n",
    "\n",
    "\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"Reduced features: {len(mi_features)}\")\n",
    "print(f\"Selected: {mi_features}\")"
   ],
   "id": "69fbfb995b1f2564",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_vif(df: pd.DataFrame):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
    "    print(vif_data)"
   ],
   "id": "f7f76f3d486e7d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_vif(X_train.drop(columns=[\"age\", \"bmi\"]))",
   "id": "d455413601af7838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vif_features = X_train.drop(columns=[\"age\", \"bmi\"]).columns.tolist()\n",
    "vif_features"
   ],
   "id": "dff9abb164f75053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=10000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=model,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5),\n",
    "    scoring=\"roc_auc\",\n",
    "    min_features_to_select=3\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "rfe_features = X_train.columns[rfecv.support_].tolist()\n",
    "ranking = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"rank\": rfecv.ranking_\n",
    "}).sort_values(\"rank\")\n",
    "\n",
    "print(\"Liczba wybranych cech:\", len(rfe_features))\n",
    "print(\"Wybrane cechy:\")\n",
    "print(rfe_features)"
   ],
   "id": "b168c5c12b7c928b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(\n",
    "    range(rfecv.min_features_to_select, len(rfecv.cv_results_[\"mean_test_score\"]) + rfecv.min_features_to_select),\n",
    "    rfecv.cv_results_[\"mean_test_score\"]\n",
    ")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"CV ROC AUC\")\n",
    "plt.title(\"RFECV performance\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "14a439b566a98172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model training",
   "id": "29568911cc43eb02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## hard coding because of stochasticity\n",
    "\n",
    "all_features = [\"age\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\",\n",
    "                \"bmi\", \"gender_Male\", \"gender_Other\", \"ever_married_Yes\",\n",
    "                \"work_type_Never_worked\", \"work_type_Private\", \"work_type_Self-employed\",\n",
    "                \"work_type_children\", \"Residence_type_Urban\",\n",
    "                \"smoking_status_formerly smoked\", \"smoking_status_never smoked\",\n",
    "                \"smoking_status_smokes\"]\n",
    "\n",
    "boruta_features = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "\n",
    "corr_features = [\"age\", \"heart_disease\", \"avg_glucose_level\", \"hypertension\",\n",
    "                 \"ever_married_Yes\", \"smoking_status_formerly smoked\",\n",
    "                 \"work_type_Self-employed\"]\n",
    "\n",
    "mi_features = [\"age\", \"hypertension\", \"gender_Other\",\n",
    "               \"work_type_Private\", \"smoking_status_formerly smoked\"]\n",
    "\n",
    "rfe_features = [\"age\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\",\n",
    "                \"bmi\", \"work_type_Never_worked\", \"work_type_children\",\n",
    "                \"Residence_type_Urban\", \"smoking_status_never smoked\",\n",
    "                \"smoking_status_smokes\"]\n",
    "\n",
    "FEATURE_SETS = {\n",
    "    \"all\": all_features,\n",
    "    \"boruta\": boruta_features,\n",
    "    \"correlation\": corr_features,\n",
    "    \"mi\": mi_features,\n",
    "    \"rfe\": rfe_features\n",
    "}"
   ],
   "id": "fa7f643080bb2f5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_all = X_train[all_features] # all features\n",
    "X_train_boruta = X_train[boruta_features].copy() # boruta selection\n",
    "X_train_corr = X_train[corr_features].copy() # cmap correlation\n",
    "X_train_mi = X_train[mi_features].copy() # correlation, mi & clustering\n",
    "X_train_rfe = X_train[rfe_features].copy() # rfecv\n",
    "\n",
    "data = {\n",
    "    \"Method\": [\n",
    "        \"All features\",\n",
    "        \"Boruta\",\n",
    "        \"Corelation\",\n",
    "        \"Mutual Information\",\n",
    "        \"RFE\"\n",
    "    ],\n",
    "    \"Feature quantity\": [\n",
    "        len(all_features),\n",
    "        len(boruta_features),\n",
    "        len(corr_features),\n",
    "        len(mi_features),\n",
    "        len(rfe_features)\n",
    "    ],\n",
    "    \"Feature name\": [\n",
    "        \", \".join(all_features),\n",
    "        \", \".join(boruta_features),\n",
    "        \", \".join(corr_features),\n",
    "        \", \".join(mi_features),\n",
    "        \", \".join(rfe_features)\n",
    "    ]\n",
    "}\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ],
   "id": "251fd8ee5cb3e1aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "storage_url = \"sqlite:///optuna_studies.db\"\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "MODELS = [\n",
    "    \"logreg\", \"knn\", \"svm\", \"gnb\", \"dt\",\n",
    "    \"rf\", \"ada\", \"gb\", \"extra\",\n",
    "    \"lgbm\", \"xgb\", \"cat\"\n",
    "]"
   ],
   "id": "fbcfac68cebe52bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sanitize_params(model, params):\n",
    "    valid = model.get_params().keys()\n",
    "    return {k: v for k, v in params.items() if k in valid}\n"
   ],
   "id": "148f7c0d577ec3ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_model_base(name, pos_weight=None):\n",
    "\n",
    "    if name == \"logreg\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                solver=\"saga\",\n",
    "                penalty=\"l2\",\n",
    "                C=1.0,\n",
    "                class_weight=\"balanced\",\n",
    "                max_iter=5000,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"svm\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"rbf\",\n",
    "                C=1.0,\n",
    "                gamma=\"scale\",\n",
    "                probability=True,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"knn\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", KNeighborsClassifier(\n",
    "                n_neighbors=15,\n",
    "                weights=\"distance\"\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"gnb\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", GaussianNB())\n",
    "        ])\n",
    "\n",
    "    if name == \"dt\":\n",
    "        return DecisionTreeClassifier(\n",
    "            max_depth=6,\n",
    "            min_samples_leaf=20,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=500,\n",
    "            max_depth=None,\n",
    "            min_samples_leaf=5,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"extra\":\n",
    "        return ExtraTreesClassifier(\n",
    "            n_estimators=500,\n",
    "            min_samples_leaf=5,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"ada\":\n",
    "        return AdaBoostClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"lgbm\":\n",
    "        return LGBMClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"xgb\":\n",
    "        return XGBClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            scale_pos_weight=pos_weight,\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"cat\":\n",
    "        return CatBoostClassifier(\n",
    "            iterations=500,\n",
    "            depth=6,\n",
    "            learning_rate=0.05,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"F1\",\n",
    "            auto_class_weights=\"Balanced\",\n",
    "            verbose=False,\n",
    "            random_seed=42\n",
    "        )\n",
    "\n",
    "    raise ValueError(name)\n"
   ],
   "id": "87dfaf6221b0606b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_model_search(trial, name):\n",
    "\n",
    "    if name == \"logreg\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                C=trial.suggest_float(\"clf__C\", 1e-3, 10, log=True),\n",
    "                l1_ratio=trial.suggest_float(\"clf__l1_ratio\", 0.0, 1.0),\n",
    "                solver=\"saga\",\n",
    "                class_weight=\"balanced\",\n",
    "                max_iter=5000,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"knn\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", KNeighborsClassifier(\n",
    "                n_neighbors=trial.suggest_int(\"clf__n_neighbors\", 3, 25),\n",
    "                weights=trial.suggest_categorical(\"clf__weights\", [\"uniform\", \"distance\"])\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"svm\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                C=trial.suggest_float(\"clf__C\", 1e-2, 10, log=True),\n",
    "                kernel=\"rbf\",\n",
    "                probability=True,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"gnb\":\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", GaussianNB(\n",
    "                var_smoothing=trial.suggest_float(\"clf__var_smoothing\", 1e-12, 1e-8, log=True)\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    if name == \"dt\":\n",
    "        return DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 2, 15),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 15),\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"extra\":\n",
    "        return ExtraTreesClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 15),\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"ada\":\n",
    "        return AdaBoostClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 400),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 1.0),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"gb\":\n",
    "        return GradientBoostingClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 400),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 2, 5),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"lgbm\":\n",
    "        return LGBMClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 16, 64),\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == \"xgb\":\n",
    "        return XGBClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    raise ValueError(name)\n"
   ],
   "id": "e8f212c269e8519f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective_catboost(trial, X, y):\n",
    "\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 200, 600),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"auto_class_weights\": \"Balanced\",\n",
    "        \"verbose\": False,\n",
    "        \"random_seed\": 42\n",
    "    }\n",
    "\n",
    "    f1s = []\n",
    "\n",
    "    for tr, va in cv.split(X, y):\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X.iloc[tr], y.iloc[tr])\n",
    "        preds = model.predict(X.iloc[va])\n",
    "        f1s.append(f1_score(y.iloc[va], preds))\n",
    "\n",
    "    return np.mean(f1s)\n"
   ],
   "id": "5a361ea26df9e814",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_model_final(name, params):\n",
    "\n",
    "    model = get_model_base(name)\n",
    "\n",
    "    clean_params = sanitize_params(model, params)\n",
    "\n",
    "    model.set_params(**clean_params)\n",
    "\n",
    "    return model\n"
   ],
   "id": "3e879fb8f9db05c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_f1(model, X, y, threshold=0.5):\n",
    "    proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (proba >= threshold).astype(int)\n",
    "    return f1_score(y, y_pred)"
   ],
   "id": "75087f6d26b33e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_best_f1_threshold(model, X, y, thresholds=np.linspace(0.01, 0.5, 50)):\n",
    "    proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_thr = 0.5\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (proba >= t).astype(int)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = t\n",
    "\n",
    "    return best_thr, best_f1\n"
   ],
   "id": "97011bd281fe4220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame(\n",
    "    index=MODELS,\n",
    "    columns=FEATURE_SETS.keys(),\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "for feature_name, feature_list in FEATURE_SETS.items():\n",
    "\n",
    "    X_train_sel = X_train[feature_list]\n",
    "    X_test_sel = X_test[feature_list]\n",
    "\n",
    "    for model_name in MODELS:\n",
    "\n",
    "        study_name = f\"{model_name}_{feature_name}_prob\"\n",
    "\n",
    "        with open(f\"models/{study_name}.pkl\", \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "        # ðŸ”¥ TU â€“ dobÃ³r progu NA TRAIN\n",
    "        best_thr, _ = find_best_f1_threshold(\n",
    "            model,\n",
    "            X_train_sel,\n",
    "            y_train\n",
    "        )\n",
    "\n",
    "        # ðŸ”¥ TU â€“ F1 NA TEST tym progiem\n",
    "        proba_test = model.predict_proba(X_test_sel)[:, 1]\n",
    "        y_pred_test = (proba_test >= best_thr).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred_test)\n",
    "        results.loc[model_name, feature_name] = f1\n",
    "\n",
    "        print(\n",
    "            f\"{model_name}_{feature_name} | \"\n",
    "            f\"thr={best_thr:.2f} | \"\n",
    "            f\"F1_test={f1:.4f}\"\n",
    "        )\n"
   ],
   "id": "dfaaec59c66d3b86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = results.sort_values(\n",
    "    by=results.columns.tolist(),\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "results"
   ],
   "id": "73c561e4742742",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"models/rf_all_prob.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 score (rf_all): {f1:.4f}\")\n"
   ],
   "id": "7d3af45eb9bdeab2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
